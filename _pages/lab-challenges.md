---
title: "Lab Challenges"
permalink: /lab-challenges/
layout: single
author_profile: true
---

## Data Analysis Lab Challenges

Here you'll find detailed documentation of data analysis challenges I've completed, showcasing my problem-solving approach and technical skills development.

---

## ðŸŽ¯ Challenge 1: Web Scraping & Data Collection

### Problem Statement
Extract structured hockey team statistics from a live website and transform the data into an analysis-ready format for further processing and visualization.

### Approach
1. **HTTP Request Handling**: Used Python's requests library to retrieve webpage content
2. **HTML Parsing**: Implemented BeautifulSoup to navigate and extract data from HTML tables
3. **Data Structuring**: Organized extracted data into Pandas DataFrame
4. **Data Export**: Saved structured data to CSV format for future analysis

### Tools Used
- **Python** with Requests library
- **BeautifulSoup** for HTML parsing
- **Pandas** for data manipulation
- **Google Colab** for development environment

### Key Lessons Learned
- Web scraping requires careful handling of website structure changes
- Data extraction from HTML tables can be automated for reproducible results
- Proper error handling is essential for robust web scraping scripts
- Structured data export enables seamless integration with analysis workflows

**[View Full Project Details â†’](/projects/web-scraping-challenge/)**

---

## ðŸŽ¯ Challenge 2: Netflix Data Wrangling

### Problem Statement
Clean and transform a messy Netflix dataset containing inconsistent formatting, missing values, and data quality issues into a reliable, analysis-ready dataset.

### Approach
1. **Data Assessment**: Comprehensive profiling to identify data quality issues
2. **Missing Value Treatment**: Strategic handling of incomplete data across multiple columns
3. **Data Standardization**: Normalization of text formats and correction of data types
4. **Feature Engineering**: Creation of new analytical features from existing data
5. **Quality Validation**: Systematic checking of data consistency and completeness

### Tools Used
- **Python** with Pandas library
- **NumPy** for numerical operations
- **Kaggle** for dataset hosting and code execution

### Key Lessons Learned
- Systematic data inspection is crucial before beginning any cleaning process
- Different missing value strategies are required for different data types
- Feature engineering can significantly enhance analytical capabilities
- Data validation ensures the reliability of downstream analysis

**[View Full Project Details â†’](/projects/netflix-data-wrangling/)**

---

## ðŸŽ¯ Challenge 3: Titanic Survival Analysis

### Problem Statement
Conduct comprehensive exploratory data analysis on the Titanic dataset to identify factors influencing passenger survival rates and uncover meaningful patterns in the data.

### Approach
1. **Initial Exploration**: Dataset profiling and structure understanding
2. **Univariate Analysis**: Individual variable distribution analysis
3. **Bivariate Analysis**: Relationship investigation between variable pairs
4. **Multivariate Analysis**: Complex pattern detection across multiple variables
5. **Statistical Testing**: Hypothesis validation and significance testing

### Tools Used
- **Python** with Pandas and NumPy
- **Matplotlib** and **Seaborn** for visualization
- **Statistical analysis** techniques
- **Jupyter Notebooks** for interactive analysis

### Key Lessons Learned
- Exploratory data analysis reveals hidden patterns not apparent in raw data
- Visualization is essential for understanding complex relationships
- Statistical testing validates observational findings
- Demographic and socio-economic factors significantly influence outcomes

**[View Full Project Details â†’](/projects/titanic-data-analysis/)**

---

## ðŸŽ¯ Challenge 4: Hotel Revenue Analytics

### Problem Statement
Develop an interactive business intelligence dashboard to track hotel performance metrics, enable data-driven decision making, and provide real-time insights into revenue optimization opportunities.

### Approach
1. **Data Integration**: Combined multiple data sources into unified data model
2. **Data Modeling**: Implemented star schema with proper relationships
3. **KPI Development**: Created calculated measures using DAX expressions
4. **Dashboard Design**: Built interactive visualizations with drill-through capabilities
5. **User Experience**: Designed intuitive interface for business users

### Tools Used
- **Power BI** for dashboard development
- **Power Query** for data transformation
- **DAX** for calculated measures and business logic
- **Star Schema** for data modeling

### Key Lessons Learned
- Business intelligence requires understanding both technical and business requirements
- Proper data modeling is foundational for effective dashboards
- Interactive features enhance user engagement and insight discovery
- Automated reporting significantly reduces manual analysis time

**[View Full Project Details â†’](/projects/hotel-revenue-analytics/)**

---

## ðŸ”§ Technical Skills Development

### Data Collection & Preparation
- Web scraping and API integration
- Data cleaning and quality assurance
- Feature engineering and transformation
- Data validation frameworks

### Analysis & Visualization
- Statistical analysis and hypothesis testing
- Exploratory data analysis methodologies
- Business intelligence dashboard development
- Data storytelling and insight communication

### Tools & Technologies Mastered
- **Programming**: Python, DAX
- **Libraries**: Pandas, NumPy, BeautifulSoup, Requests, Matplotlib, Seaborn
- **BI Tools**: Power BI, Power Query
- **Platforms**: Google Colab, Kaggle, Jupyter Notebooks

---

**Explore all my projects in detail: [View Complete Project Portfolio â†’](/projects/)**

*These lab challenges demonstrate my systematic approach to solving data problems and my commitment to continuous skill development in data analytics.*
